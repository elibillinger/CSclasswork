{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 7: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0031320310003973-gr1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Description\n",
    "\n",
    "In this project, we are going to explore Random Forest Regressors for predicting the weather, specifically the temperature. You'll load the data in, set up a Random Forest, then test its performance on both the original data set and new data. This new data will be the current weather conditions and will come from an Application Programming Interface(API).\n",
    "\n",
    "### Grading\n",
    "\n",
    "For grading purposes, we will clear all outputs from all your cells and then run them all from the top.  Please test your notebook in the same fashion before turning it in.\n",
    "\n",
    "### Submitting Your Solution\n",
    "\n",
    "To submit your notebook, first clear all the cells (this won't matter too much this time, but for larger data sets in the future, it will make the file smaller).  Then use the File->Download As->Notebook to obtain the notebook file.  Finally, submit the notebook file on Canvas.\n",
    "\n",
    "## Side note:\n",
    "Most of the tasks below require you use specific variable names. This is so that the cells with \"assert\" statements in them can check if you did the tasks correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might be necessary\n",
    "#!pip3 install pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pydot\n",
    "import requests\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "You're given a csv file, ```temps.csv```, with weather data in Seattle from 2016.\n",
    "\n",
    "## Tasks:\n",
    "- Read in the file into a dataframe called `data`\n",
    "- Run `get_dummies()` on the day of the week\n",
    "- Specify the predictors (features) and targets:\n",
    " - Predictors: 'temp_1', 'temp_2', 'average', and the days of the week\n",
    " - Target: 'actual' (the actual temperature on the specified date)\n",
    "- Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data = pd.DataFrame(pd.read_csv(\"temps.csv\"))\n",
    "\n",
    "# get_dummies\n",
    "data = pd.get_dummies(data,columns= ['week'])\n",
    "\n",
    "# train_test_split\n",
    "features = ['temp_1','temp_2','week_Fri','week_Mon','week_Sat','week_Sun','week_Thurs','week_Tues','week_Wed']\n",
    "target = ['actual']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(data[features],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "for column in ['week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']:\n",
    "    assert column in data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "\n",
    "### Background\n",
    "Random Forests, aka Random Decision Trees, are an example of \"ensemble: learning methods. They operate by constructing many decision trees at once and outputting their mean prediction. This is useful because decision trees on their own are prone to overfitting. Random Forests are most often used for classification and regression, but today, we'll only be doing regression.\n",
    "\n",
    "### Tasks \n",
    "- Initialize a `RandomForestRegressor` with 1000 estimators and a max_depth of 10. The model will perform well with these values, but you can always change them later. Store the regressor in the variable `rf_clf`.\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html \n",
    "- Fit the model with `rf_clf.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize model\n",
    "rf_clf = RandomForestRegressor(n_estimators = 1000,max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "rf_clf.fit(X_train,Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualization\n",
    "\n",
    "The next cell plots an image of one of the trees in the forest. It also  \n",
    "saves a png image file in the same directory as this jupyter notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "index = 5\n",
    "tree = rf_clf.estimators_[index]\n",
    "from IPython.display import display\n",
    "columns = list(X_train.columns)\n",
    "#display(graphviz.Source(export_graphviz(tree, feature_names=columns, class_names=True, out_file=None)))\n",
    "\n",
    "# Save image to png file\n",
    "#export_graphviz(tree, out_file = 'tree.dot', feature_names = features, rounded = True, precision = 1)\n",
    "#(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "#graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Visualization\n",
    "\n",
    "Plot the learned importance of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importances\n",
    "importances = list(rf_clf.feature_importances_)\n",
    "labeled_importances = [(feature, round(importance, 2)) for feature, importance in zip(features, importances)]\n",
    "indices = range(len(importances))\n",
    "plt.bar(indices, importances, orientation = 'vertical')\n",
    "plt.title('feature importances')\n",
    "plt.xticks(indices, features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "First, we are going to use the test set to make predictions, same as always. Then we're going to get new data from an API.\n",
    "\n",
    "### Tasks\n",
    "- Find the R^2 value. Do this with `model.score()` or `sklearn.metrics.r2_score()` and save to a variable called `r2`. \n",
    "- Find the explained variance with `sklearn.metrics.explained_variance_score()` and save to a variable called `ev`.\n",
    "\n",
    "For both of these metrics, the closer to 1, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "r2 = rf_clf.score(X_test,Y_test)\n",
    "#print(r2)\n",
    "ev = sklearn.metrics.explained_variance_score(Y_test,rf_clf.predict(X_test))\n",
    "#print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert r2 > 0.7\n",
    "assert ev > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "#### Background\n",
    "An application programming interface (API) is just another way to gather data by letting clients (us and our computers) programmatically interact with servers. Today, we're going to be using a weather API for getting the current temp of a location.\n",
    "\n",
    "##### JSON\n",
    "JavaScript Object Notation is a very popular data format, especially for APIs. It appears very similar to Python's dictionaries, with curly braces to start, then key-value pairs of data. An example for a person could be:\n",
    "```\n",
    "{\n",
    "    'firstname': 'John',\n",
    "    'lastname': 'Doe',\n",
    "    'age': 55,\n",
    "    'retired': true,\n",
    "    'addresses': ['123 street', '456 street']\n",
    "}\n",
    "```\n",
    "When we make an API request, the server will handle it, then respond with a bunch of JSON, which we can grab exactly what we want from.\n",
    "\n",
    "#### OpenWeatherMap API\n",
    "Let's use the OpenWeatherMap API to get the current weather. The documentation is [here](https://openweathermap.org/current). To do so, we use the `requests` library. Making a request is very similar to going to a website in a browser -- a URL points to a location or resource on a server and that server fulfills the tasks we ask it to.\n",
    "<br>\n",
    "The URL is `'http://api.openweathermap.org/data/2.5/weather?q={city name},{country code}'`, where we fill in the city name and country code(without the curly braces).\n",
    "<br>\n",
    "An example response the API would send: https://samples.openweathermap.org/data/2.5/weather?q=London,uk&appid=b6907d289e10d714a6e88b30761fae22\n",
    "\n",
    "\n",
    "#### Your tasks\n",
    "- Fill in the URL with the city and country_code. Set this to variable `url`.\n",
    "- Use `requests.get()` to make request. Set the output to variable `r`. This takes two arguments: one called `url`, which is the URL above, and one called `params`, which is a dictionary of parameters, which in this case (and with most APIs) is a unique key that authenticates us and is an indication to use imperial units instead of Kelvin.\n",
    "- Read the response with `r.text`\n",
    "- Parse the response into JSON with `json.loads(response)`\n",
    "- If you want, print the JSON out, formatted nicely with `pprint(response)`\n",
    "- Get the current temperature from the JSON like you would a python dictionary. For example, `person['age']` if we were using the example JSON above. Set this value to the variable `current_temp`\n",
    "- Compare the current temperature to the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'seattle'\n",
    "country_code = 'us'\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?q={city},{country_code}'\n",
    "parameters = {\n",
    "    'APPID' : '2dbcde0477e10f32f587960671d2f32e',\n",
    "    'units' : 'imperial'\n",
    "}\n",
    "\n",
    "response = r.text\n",
    "response=json.loads(response)\n",
    "current_temp = response['main']['temp']\n",
    "try:\n",
    "    r = requests.get(url,parameters)   \n",
    "except Exception as e:\n",
    "   print(e)\n",
    "#print(current_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert response\n",
    "assert current_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to compare current weather data to last year. The code given below gets the day of the year it is today, extracts that row from our original csv data, and splits that row into features and targets.\n",
    "\n",
    "#### Your task\n",
    "- Use the your random forest model to predict the temperature on this day last year and compare that prediction to the current temperature.\n",
    "- Divide that comparision (the difference) by the current temperature to determine what percent error we have. Save this to the variable `error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_year = datetime.now().timetuple().tm_yday\n",
    "last_year_features = np.array([data.loc[day_of_year, features]])\n",
    "last_year_temp = data.at[day_of_year, 'actual']\n",
    "\n",
    "predicted_temp = rf_clf.predict(last_year_features)\n",
    "error = (predicted_temp-current_temp)/(current_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This isn't really the error, since we're compaing the same day in different years. This is due to the limitations of the free tier of this API, but we can still get a *decent* idea of how well the model faired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Save your response to the questions below in the variable `response`, in the next cell.\n",
    "- Do you think the model did \"well\"? Why or why not?\n",
    "- Whether or not the model did well, what are some ways we could make it even better?\n",
    "- What are some limitations to this model? Could we avoid/prevent them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = 'I think that the model did well because the explained variance was close to one and when testing the predicted temp was also close to the real temp. It could be better if dimensionality reduction was applied to it. Some limitaions of this model are that it is randomized so it will never be exact and this cannot be prevented.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert len(response) > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
